{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 1: _Индекс_\n",
    "\n",
    "## 0. Intro\n",
    "\n",
    "### 0.1 &emsp; Чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__\n",
    "\n",
    "```python\n",
    "fpath = \"fpath.txt\"\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, \"r\") as f:  \n",
    "    text = f.read() \n",
    "\n",
    "# по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, \"r\") as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "# по строкам, без \\n   \n",
    "with open(fpath, \"r\") as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "# not recommended  \n",
    "file = open(txt_fpath, \"r\")  \n",
    "text = file.read()    \n",
    "file.close() \n",
    "```\n",
    "\n",
    "### 0.2 &emsp; Работа с файлами и папками\n",
    "#### os.path  \n",
    "Путь до файла:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath(\"fpath.txt\"))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename(\"/your/path/to/folder/with/fpath.txt\"))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists(\"your/path/to/any/folder/\"))\n",
    "```\n",
    "\n",
    "#### os.listdir  \n",
    "* Возвращает список файлов в данной директории:\n",
    "\n",
    "```python\n",
    "main_dir = \"/your/path/to/folder/with/folders/\"\n",
    "os.listdir(main_dir)\n",
    "```\n",
    "\n",
    "* Сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл:\n",
    "```python\n",
    "[main_dir + fpath for fpath in os.listdir(main_dir)]\n",
    "```\n",
    "\n",
    "* Не забывайте исключать системные директории, такие как `.DS_Store`\n",
    "```python\n",
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not \".DS_Store\" in fpath]\n",
    "```\n",
    "\n",
    "#### os.walk\n",
    "`root` — начальная директория  \n",
    "`dirs` — список поддиректорий (папок)   \n",
    "`files` — список файлов в этих поддиректориях  \n",
    "\n",
    "```python\n",
    "main_dir = \"/your/path/to/folder/with/folders/\"\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "```\n",
    "\n",
    "> __os.walk__ возвращает генератор. Это значит, что получить его элементы можно, только проитерировавшись по нему, но его легко можно превратить в `list` и увидеть все его значения\n",
    "\n",
    "```python\n",
    "list(os.walk(main_dir))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. &emsp; Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 &emsp; __Задача__: \n",
    "\n",
    "**Получите обратный индекс для коллекции документов.**\n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия — один документ.\n",
    "\n",
    "Скачать корпус можно [тут](https://yadi.sk/d/k_M7n63A3adGSz).\n",
    "\n",
    "Этапы:   \n",
    "\n",
    "1. получить коллекцию документов\n",
    "2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "4. получить обратный индекс в виде словаря, где ключ — нормализованное слово, значение — список файлов, в которых это слово встречается\n",
    "5. вывести кусочек индекса в виде таблицы \n",
    "6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы\n",
    "\n",
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "```python \n",
    "for i, element in enumerate(your_list): \n",
    "    ... \n",
    "```    \n",
    "Иногда для получения элемента делают так — `your_list[i]`, старайтесь этого избегать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"./Friends\"\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for season_dir in dirs:\n",
    "        half_path = root + \"/\" + season_dir\n",
    "        files_list += [half_path + \"/\" + fpath for fpath in os.listdir(half_path) if not \".DS_Store\" in fpath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### _check : в коллекции должно быть 165 файлов\n",
    "len(files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 &emsp; Терм-документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_punct = re.compile(\"[\" + string.punctuation + \"]\")\n",
    "reg_num = re.compile(\"[0-9]+\")\n",
    "reg_latin = re.compile(\"[a-z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\ufeff\", \"\")\n",
    "    text = reg_punct.sub(\"\", text)\n",
    "    text = reg_num.sub(\"\", text)\n",
    "    text = reg_latin.sub(\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=0, max_df=1)\n",
    "reg_episode = re.compile(\"[0-9]x[0123456789-]+\")\n",
    "\n",
    "texts = []\n",
    "episodes = []\n",
    "term_doc_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for script_path in files_list:\n",
    "    with open(script_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text_raw = f.read()\n",
    "    episode = re.search(reg_episode, script_path).group(0)\n",
    "    episodes.append(episode)\n",
    "    text = preprocessing(text_raw)\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ааааааа</th>\n",
       "      <th>аааааау</th>\n",
       "      <th>ааааах</th>\n",
       "      <th>аарон</th>\n",
       "      <th>аббатстве</th>\n",
       "      <th>аббатство</th>\n",
       "      <th>абонемент</th>\n",
       "      <th>абрикосы</th>\n",
       "      <th>абсурд</th>\n",
       "      <th>абсурдная</th>\n",
       "      <th>...</th>\n",
       "      <th>ёй</th>\n",
       "      <th>ёкнуло</th>\n",
       "      <th>ёлками</th>\n",
       "      <th>ёлке</th>\n",
       "      <th>ёлки</th>\n",
       "      <th>ёлочных</th>\n",
       "      <th>ёпэрэсотэ</th>\n",
       "      <th>ёрл</th>\n",
       "      <th>ёрш</th>\n",
       "      <th>ёще</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2x08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2x20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2x24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2x16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2x07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ааааааа  аааааау  ааааах  аарон  аббатстве  аббатство  абонемент  \\\n",
       "episode                                                                     \n",
       "2x08           0        0       0      0          0          0          0   \n",
       "2x20           0        0       0      0          0          0          0   \n",
       "2x24           0        0       0      0          0          0          0   \n",
       "2x16           0        0       0      0          0          0          0   \n",
       "2x07           0        0       0      0          0          0          0   \n",
       "\n",
       "         абрикосы  абсурд  абсурдная ...   ёй  ёкнуло  ёлками  ёлке  ёлки  \\\n",
       "episode                              ...                                    \n",
       "2x08            0       0          0 ...    0       0       0     0     0   \n",
       "2x20            0       0          0 ...    0       0       0     0     0   \n",
       "2x24            0       0          0 ...    0       0       0     0     0   \n",
       "2x16            0       0          0 ...    0       0       0     0     0   \n",
       "2x07            0       0          0 ...    0       0       0     0     0   \n",
       "\n",
       "         ёлочных  ёпэрэсотэ  ёрл  ёрш  ёще  \n",
       "episode                                     \n",
       "2x08           0          0    0    0    0  \n",
       "2x20           0          0    0    0    0  \n",
       "2x24           0          0    0    0    0  \n",
       "2x16           0          0    0    0    0  \n",
       "2x07           0          0    0    0    0  \n",
       "\n",
       "[5 rows x 19340 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix = pd.DataFrame(cv.fit_transform(texts).A , columns=cv.get_feature_names(), index=None)\n",
    "term_doc_matrix[\"episode\"] = episodes\n",
    "term_doc_matrix = term_doc_matrix.set_index(term_doc_matrix[\"episode\"])\n",
    "del term_doc_matrix[\"episode\"]\n",
    "term_doc_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 &emsp; Булев поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это простой поиск по одному токену\n",
    "def simple_boolean_search(query) -> list:\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = term_doc_matrix[query]\n",
    "    except:\n",
    "        print(\"Такого слова не нашлось.\")\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запросы \n",
    "input_text = [\n",
    "    \"Моника & Фиби & Рэйчел & Чендлер & Джои & Росс\",\n",
    "    \"(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс\", \n",
    "    \"(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = input_text[0].split(\" & \")\n",
    "result = set(boolean_search(queries[0], term_doc_matrix))\n",
    "for query in queries[1:]:\n",
    "    res = set(boolean_search(query, term_doc_matrix))\n",
    "    result = result.intersection(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index() -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    inv_index = defaultdict()\n",
    "    inv_index = inv_index.setdefault([])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim() -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    return \n",
    "\n",
    "\n",
    "def get_search_result() -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
